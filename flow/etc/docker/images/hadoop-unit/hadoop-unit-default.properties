#HADOOP_HOME=/opt/hadoop

tmp.dir.path=/root/hadoop-unit-data/

zookeeper.artifactId=fr.jetoile.hadoop:hadoop-unit-zookeeper:3.7
zookeeper.mainClass=fr.jetoile.hadoopunit.component.ZookeeperBootstrap
zookeeper.metadataClass=fr.jetoile.hadoopunit.component.ZookeeperMetadata

hdfs.artifactId=fr.jetoile.hadoop:hadoop-unit-hdfs:3.7
hdfs.mainClass=fr.jetoile.hadoopunit.component.HdfsBootstrap
hdfs.metadataClass=fr.jetoile.hadoopunit.component.HdfsMetadata

hdfs3.artifactId=fr.jetoile.hadoop:hadoop-unit-hdfs3:3.7
hdfs3.mainClass=fr.jetoile.hadoopunit.component.Hdfs3Bootstrap
hdfs3.metadataClass=fr.jetoile.hadoopunit.component.Hdfs3Metadata

alluxio.artifactId=fr.jetoile.hadoop:hadoop-unit-alluxio:3.7
alluxio.mainClass=fr.jetoile.hadoopunit.component.AlluxioBootstrap
alluxio.metadataClass=fr.jetoile.hadoopunit.component.AlluxioMetadata

hivemeta.artifactId=fr.jetoile.hadoop:hadoop-unit-hive:3.7
hivemeta.mainClass=fr.jetoile.hadoopunit.component.HiveMetastoreBootstrap
hivemeta.metadataClass=fr.jetoile.hadoopunit.component.HiveMetastoreMetadata

hiveserver2.artifactId=fr.jetoile.hadoop:hadoop-unit-hive:3.7
hiveserver2.mainClass=fr.jetoile.hadoopunit.component.HiveServer2Bootstrap
hiveserver2.metadataClass=fr.jetoile.hadoopunit.component.HiveServer2Metadata

hivemeta3.artifactId=fr.jetoile.hadoop:hadoop-unit-hivemeta3:3.7
hivemeta3.mainClass=fr.jetoile.hadoopunit.component.HiveMetastore3Bootstrap
hivemeta3.metadataClass=fr.jetoile.hadoopunit.component.HiveMetastore3Metadata

hiveserver23.artifactId=fr.jetoile.hadoop:hadoop-unit-hiveserver23:3.7
hiveserver23.mainClass=fr.jetoile.hadoopunit.component.HiveServer23Bootstrap
hiveserver23.metadataClass=fr.jetoile.hadoopunit.component.HiveServer23Metadata

kafka.artifactId=fr.jetoile.hadoop:hadoop-unit-kafka:3.7
kafka.mainClass=fr.jetoile.hadoopunit.component.KafkaBootstrap
kafka.metadataClass=fr.jetoile.hadoopunit.component.KafkaMetadata

hbase.artifactId=fr.jetoile.hadoop:hadoop-unit-hbase:3.7
hbase.mainClass=fr.jetoile.hadoopunit.component.HBaseBootstrap
hbase.metadataClass=fr.jetoile.hadoopunit.component.HBaseMetadata

oozie.artifactId=fr.jetoile.hadoop:hadoop-unit-oozie:3.7
oozie.mainClass=fr.jetoile.hadoopunit.component.OozieBootstrap
oozie.metadataClass=fr.jetoile.hadoopunit.component.OozieMetadata

solr.artifactId=fr.jetoile.hadoop:hadoop-unit-solr:3.7
solr.mainClass=fr.jetoile.hadoopunit.component.SolrBootstrap
solr.metadataClass=fr.jetoile.hadoopunit.component.SolrMetadata

solrcloud.artifactId=fr.jetoile.hadoop:hadoop-unit-solrcloud:3.7
solrcloud.mainClass=fr.jetoile.hadoopunit.component.SolrCloudBootstrap
solrcloud.metadataClass=fr.jetoile.hadoopunit.component.SolrCloudMetadata

cassandra.artifactId=fr.jetoile.hadoop:hadoop-unit-cassandra:3.7
cassandra.mainClass=fr.jetoile.hadoopunit.component.CassandraBootstrap
cassandra.metadataClass=fr.jetoile.hadoopunit.component.CassandraMetadata

mongodb.artifactId=fr.jetoile.hadoCOPY hadoop.properties /root/hadoop-unit-standalone/confop:hadoop-unit-mongodb:3.7
mongodb.mainClass=fr.jetoile.hadoopunit.component.MongoDbBootstrap
mongodb.metadataClass=fr.jetoile.hadoopunit.component.MongoDbMetadata

elasticsearch.artifactId=fr.jetoile.hadoop:hadoop-unit-elasticsearch:3.7
elasticsearch.mainClass=fr.jetoile.hadoopunit.component.ElasticSearchBootstrap
elasticsearch.metadataClass=fr.jetoile.hadoopunit.component.ElasticSearchMetadata

neo4j.artifactId=fr.jetoile.hadoop:hadoop-unit-neo4j:3.7
neo4j.mainClass=fr.jetoile.hadoopunit.component.Neo4jBootstrap
neo4j.metadataClass=fr.jetoile.hadoopunit.component.Neo4jMetadata

knox.artifactId=fr.jetoile.hadoop:hadoop-unit-knox:3.7
knox.mainClass=fr.jetoile.hadoopunit.component.KnoxBootstrap
knox.metadataClass=fr.jetoile.hadoopunit.component.KnoxMetadata

redis.artifactId=fr.jetoile.hadoop:hadoop-unit-redis:3.7
redis.mainClass=fr.jetoile.hadoopunit.component.RedisBootstrap
redis.metadataClass=fr.jetoile.hadoopunit.component.RedisMetadata

yarn.artifactId=fr.jetoile.hadoop:hadoop-unit-yarn:3.7
yarn.mainClass=fr.jetoile.hadoopunit.component.YarnBootstrap
yarn.metadataClass=fr.jetoile.hadoopunit.component.YarnMetadata

yarn3.artifactId=fr.jetoile.hadoop:hadoop-unit-yarn3:3.7
yarn3.mainClass=fr.jetoile.hadoopunit.component.Yarn3Bootstrap
yarn3.metadataClass=fr.jetoile.hadoopunit.component.Yarn3Metadata

confluent_kafka.artifactId=fr.jetoile.hadoop:hadoop-unit-confluent:3.7
confluent_kafka.mainClass=fr.jetoile.hadoopunit.component.ConfluentKafkaBootstrap
confluent_kafka.metadataClass=fr.jetoile.hadoopunit.component.ConfluentKafkaMetadata

confluent_schemaregistry.artifactId=fr.jetoile.hadoop:hadoop-unit-confluent:3.7
confluent_schemaregistry.mainClass=fr.jetoile.hadoopunit.component.ConfluentSchemaRegistryBootstrap
confluent_schemaregistry.metadataClass=fr.jetoile.hadoopunit.component.ConfluentSchemaRegistryMetadata

confluent_ksql_rest.artifactId=fr.jetoile.hadoop:hadoop-unit-confluent:3.7
confluent_ksql_rest.mainClass=fr.jetoile.hadoopunit.component.ConfluentKsqlRestBootstrap
confluent_ksql_rest.metadataClass=fr.jetoile.hadoopunit.component.ConfluentKsqlRestMetadata

confluent_kafka_rest.artifactId=fr.jetoile.hadoop:hadoop-unit-confluent-rest:3.7
confluent_kafka_rest.mainClass=fr.jetoile.hadoopunit.component.ConfluentKafkaRestBootstrap
confluent_kafka_rest.metadataClass=fr.jetoile.hadoopunit.component.ConfluentKafkaRestMetadata

docker.artifactId=fr.jetoile.hadoop:hadoop-unit-docker:3.7
docker.mainClass=fr.jetoile.hadoopunit.component.DockerBootstrap
docker.metadataClass=fr.jetoile.hadoopunit.component.DockerMetadata

docker_compose.artifactId=fr.jetoile.hadoop:hadoop-unit-dockercompose:3.7
docker_compose.mainClass=fr.jetoile.hadoopunit.component.DockerComposeBootstrap
docker_compose.metadataClass=fr.jetoile.hadoopunit.component.DockerComposeMetadata

pulsar_standalone.artifactId=fr.jetoile.hadoop:hadoop-unit-pulsar-standalone:3.7
pulsar_standalone.mainClass=fr.jetoile.hadoopunit.component.PulsarStandaloneBootstrap
pulsar_standalone.metadataClass=fr.jetoile.hadoopunit.component.PulsarStandaloneMetadata

pulsar.artifactId=fr.jetoile.hadoop:hadoop-unit-pulsar:3.7
pulsar.mainClass=fr.jetoile.hadoopunit.component.PulsarBootstrap
pulsar.metadataClass=fr.jetoile.hadoopunit.component.PulsarMetadata

bookkeeper.artifactId=fr.jetoile.hadoop:hadoop-unit-bookkeeper:3.7
bookkeeper.mainClass=fr.jetoile.hadoopunit.component.BookkeeperBootstrap
bookkeeper.metadataClass=fr.jetoile.hadoopunit.component.BookkeeperMetadata

maven.central.repo=https://repo.maven.apache.org/maven2/
maven.local.repo=/root/hadoop-unit-data/.m2/repository

#maven.debug=true

# Zookeeper
zookeeper.temp.dir=/embedded_zk
zookeeper.host=0.0.0.0
zookeeper.port=22010

zookeeper.client.host=127.0.0.1


# Hive
hive.scratch.dir=/hive_scratch_dir
hive.warehouse.dir=/tmp/warehouse_dir

# Hive Metastore
hive.metastore.hostname=0.0.0.0
hive.metastore.port=20102
hive.metastore.derby.db.dir=/metastore_db

hive.metastore.client.hostname=127.0.0.1

# Hive Server2
hive.server2.hostname=0.0.0.0
hive.server2.port=20103

hive.server2.client.hostname=127.0.0.1

# Hive Test
hive.test.database.name=default
hive.test.table.name=test_table


# Hive3
hive3.scratch.dir=/hive_scratch_dir
hive3.warehouse.dir=/tmp/warehouse_dir

# Hive Metastore 3
hive3.metastore.hostname=0.0.0.0
hive3.metastore.port=20102
hive3.metastore.derby.db.dir=metastore_db

hive3.metastore.client.hostname=localhost

# Hive Server2 3
hive3.server2.hostname=0.0.0.0
hive3.server2.port=20103

hive3.server2.client.hostname=localhost

# Hive Test 3
hive3.test.database.name=default
hive3.test.table.name=test_table


# HDFS
hdfs.namenode.host=0.0.0.0
hdfs.namenode.port=20112
hdfs.namenode.http.port=50070
hdfs.temp.dir=/embedded_hdfs
hdfs.num.datanodes=1
hdfs.enable.permissions=false
hdfs.format=true
hdfs.enable.running.user.as.proxy.user=true
hdfs.datanode.address=0.0.0.0:50010
hdfs.datanode.http.address=0.0.0.0:50075
hdfs.datanode.ipc.address=0.0.0.0:50020

# HDFS Test
hdfs.test.file=/tmp/testing
hdfs.test.string=TESTING

hdfs.namenode.client.host=127.0.0.1
hdfs.datanode.client.address=127.0.0.1:50010
hdfs.datanode.http.client.address=127.0.0.1:50075
hdfs.datanode.ipc.client.address=127.0.0.1:50020


# HDFS3
hdfs3.namenode.host=0.0.0.0
hdfs3.namenode.port=20112
hdfs3.namenode.http.port=50070
hdfs3.temp.dir=/embedded_hdfs
hdfs3.num.datanodes=1
hdfs3.enable.permissions=false
hdfs3.format=true
hdfs3.enable.running.user.as.proxy.user=true
hdfs3.datanode.address=0.0.0.0:50010
hdfs3.datanode.http.address=0.0.0.0:50075
hdfs3.datanode.ipc.address=0.0.0.0:50020

# HDFS3 Test
hdfs3.test.file=/tmp/testing
hdfs3.test.string=TESTING

hdfs3.namenode.client.host=127.0.0.1
hdfs3.datanode.client.address=127.0.0.1:50010
hdfs3.datanode.http.client.address=127.0.0.1:50075
hdfs3.datanode.ipc.client.address=127.0.0.1:50020

# HBase
hbase.master.port=25111
hbase.master.info.port=-1
hbase.num.region.servers=1
hbase.root.dir=/embedded_hbase
hbase.znode.parent=/hbase-unsecure
hbase.wal.replication.enabled=false

# HBase REST
hbase.rest.port=28000
hbase.rest.readonly=false
hbase.rest.info.port=28080
hbase.rest.host=0.0.0.0
hbase.rest.threads.max=100
hbase.rest.threads.min=2

hbase.rest.client.host=127.0.0.1

# HBase Test
hbase.test.table.name=hbase_test_table
hbase.test.col.family.name=cf1
hbase.test.col.qualifier.name=cq1
hbase.test.num.rows.to.put=50

# Kafka
kafka.hostname=0.0.0.0
kafka.port=20111

# Kafka Test
kafka.test.topic=testtopic
kafka.test.message.count=10
kafka.test.broker.id=1
kafka.test.temp.dir=/embedded_kafka

#SolR + SolRCloud
solr.dir=solr

#SolR
solr.collection.internal.name=collection1_shard1_replica1

#SolRCloud
solr.collection.name=collection1
solr.cloud.port=8983





# YARN
yarn.num.node.managers=1
yarn.num.local.dirs=1
yarn.num.log.dirs=1
yarn.resource.manager.address=0.0.0.0:37001
yarn.resource.manager.hostname=0.0.0.0
yarn.resource.manager.scheduler.address=0.0.0.0:37002
yarn.resource.manager.resource.tracker.address=0.0.0.0:37003
yarn.resource.manager.webapp.address=0.0.0.0:37004
yarn.use.in.jvm.container.executor=false

yarn.resource.manager.client.address=localhost:37001
yarn.resource.manager.client.hostname=localhost
yarn.resource.manager.scheduler.client.address=localhost:37002
yarn.resource.manager.resource.tracker.client.address=localhost:37003
yarn.resource.manager.webapp.client.address=localhost:37004


# YARN3
yarn3.num.node.managers=1
yarn3.num.local.dirs=1
yarn3.num.log.dirs=1
yarn3.resource.manager.address=0.0.0.0:37001
yarn3.resource.manager.hostname=0.0.0.0
yarn3.resource.manager.scheduler.address=0.0.0.0:37002
yarn3.resource.manager.resource.tracker.address=0.0.0.0:37003
yarn3.resource.manager.webapp.address=0.0.0.0:37004
yarn3.use.in.jvm.container.executor=false

yarn3.resource.manager.client.address=localhost:37001
yarn3.resource.manager.client.hostname=localhost
yarn3.resource.manager.scheduler.client.address=localhost:37002
yarn3.resource.manager.resource.tracker.client.address=localhost:37003
yarn3.resource.manager.webapp.client.address=localhost:37004

# MR
mr.job.history.address=0.0.0.0:37005
mr.job.history.client.address=127.0.0.1:37005

# Oozie
oozie.tmp.dir=/oozie_tmp
oozie.test.dir=/embedded_oozie
oozie.home.dir=/oozie_home
oozie.username=blah
oozie.groupname=testgroup
oozie.hdfs.share.lib.dir=/tmp/share_lib
oozie.share.lib.create=true
oozie.local.share.lib.cache.dir=/tmp/share_lib_cache
oozie.purge.local.share.lib.cache=false
oozie.sharelib.path=~/github
oozie.sharelib.name=oozie-4.2.0.2.6.5.0-292-distro.tar.gz
oozie.port=20113
oozie.host=0.0.0.0
oozie.sharelib.component=OOZIE,MAPREDUCE_STREAMING,SPARK
#oozie.sharelib.component=OOZIE,HCATALOG,DISTCP,MAPREDUCE_STREAMING,PIG,HIVE,HIVE2,SQOOP,SPARK

oozie.client.host=localhost

# ElasticSearch
elasticsearch.version=6.7.1
elasticsearch.ip=127.0.0.1
elasticsearch.http.port=14433
elasticsearch.tcp.port=14533
elasticsearch.index.name=test_index
elasticsearch.cluster.name=elasticsearch
#elasticsearch.download.url=https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.4.3.zip

# MongoDB
mongo.ip=0.0.0.0
mongo.port=13333
mongo.database.name=test_database
mongo.collection.name=test_collection

# Cassandra
cassandra.listen.address.ip=127.0.0.1
cassandra.rpc.address.ip=0.0.0.0
cassandra.broadcast.address.ip=127.0.0.1
cassandra.broadcast.rpc.address.ip=127.0.0.1
cassandra.port=13433
cassandra.temp.dir=/embedded_cassandra

cassandra.listen.address.client.ip=127.0.0.1

# Neo4j
neo4j.ip=0.0.0.0
neo4j.port=13533
neo4j.temp.dir=/embedded_neo4j

# KNOX
knox.host=0.0.0.0
knox.port=8888
knox.path=gateway
knox.cluster=mycluster
knox.home.dir=/embedded_knox
knox.service=namenode,webhdfs,webhbase
#knox.service=namenode,webhdfs,webhbase,oozie

# Alluxio
#alluxio.work.dir=/tmp/alluxio
alluxio.work.dir=hdfs://127.0.0.1:20112/alluxio
alluxio.hostname=127.0.0.1
alluxio.master.port=14001
alluxio.master.web.port=14002
alluxio.proxy.web.port=14100
alluxio.worker.web.port=14003
alluxio.worker.data.port=14004
alluxio.worker.port=14005
alluxio.webapp.directory=conf/alluxio/webapp


# Redis
redis.port=6379
redis.download.url=http://download.redis.io/releases/
redis.version=5.0.4
redis.cleanup.installation=false
redis.temp.dir=/redis
redis.type=SERVER
#redis.type=CLUSTER
#redis.type=MASTER_SLAVE
#redis.type=SENTINEL
#redis.slave.ports=6380
#redis.sentinel.ports=36479,36480,36481,36482,36483




# Confluent
confluent.schemaregistry.port=8081
confluent.schemaregistry.host=0.0.0.0
confluent.schemaregistry.kafkastore.topic=_schema
confluent.schemaregistry.debug=false

confluent.kafka.log.dirs=/kafka-logs
confluent.kafka.broker.id=0
confluent.kafka.port=22222
confluent.kafka.host=0.0.0.0

confluent.rest.host=0.0.0.0
confluent.rest.port=8082

confluent.ksql.host=0.0.0.0
confluent.ksql.port=8083

confluent.schemaregistry.client.host=127.0.0.1
confluent.kafka.client.host=127.0.0.1
confluent.rest.client.host=127.0.0.1
confluent.ksql.client.host=127.0.0.1

# Docker
docker.imagename=alpine:3.2
docker.exposedports=80
docker.envs=MAGIC_NUMBER:42
docker.labels=MAGIC_NUMBER:42
docker.command=/bin/sh, -c, while true; do echo \"$MAGIC_NUMBER\" | nc -l -p 80; done
docker.fixed.exposedports=21300:80
#docker.classpath.resources.mapping=hadoop-unit-default.properties:/hadoop-unit-default.properties:READ_ONLY

# Docker compose
dockercompose.filename=conf/docker-compose.yml
#dockercompose.exposedports=zoo:2181,resourcemanager:8088
dockercompose.local=false



# Pulsar
pulsar.zookeeper.temp.dir=/pulsar/embedded_zk
pulsar.zookeeper.port=22020

pulsar.ip=0.0.0.0
pulsar.port=22022
pulsar.temp.dir=/pulsar
pulsar.name=pulsar-cluster-1
pulsar.http.port=22023
pulsar.streamer.storage.port=4181

pulsar.client.ip=127.0.0.1

# BookKeeper
bookkeeper.ip=0.0.0.0
bookkeeper.port=31810
bookkeeper.http.port=31900
bookkeeper.temp.dir=/bookeeper

bookkeeper.client.ip=127.0.0.1
